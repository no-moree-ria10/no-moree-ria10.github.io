---
title: Kaggle DSB2019参加の記録（初参加初メダルになりたかった話）
tags: Kaggle
---

## TL;DL;
* kaggleに[DSB2019](https://www.kaggle.com/c/data-science-bowl-2019)に初参加した
* publicLBでは最終日前日にブロンズ圏内に入ったが、その後圏外→shake downして800位（ぴったり！）という散々な結果に終わった
* deepなモデルが勾配ブースティング木に勝つには難しいことが分かった
    * 溶かしたお金は5万円ほどコスパも悪いぞい
* 弊社では教育アプリの開発、データ分析、機械学習エンジニアを求めています。DMください。


## 参加のモチベーション
* 仕事で教育アプリを作っているが、学習履歴データの分析需要がありました
    * 具体的には進捗の分析、苦手分野の補強に関するレコメンドなど。
* 趣味レベルの機械学習の知識（validationや最適化、ライブラリの基礎）はありましたが、業務での機械学習は未経験だったため、kaggleで１回慣らしとくかと思っていたところ、
まさに教育アプリの成績予測コンペである[DSB2019](https://www.kaggle.com/c/data-science-bowl-2019)
を発見しました
    * 最高かよと思いながら参加しました。
    
## 最終的に採用した戦略
* ハイスコアカーネル+自前のモデルの平均アンサンブル
    * このハイスコアカーネルが地雷？だったらしく、big shake downした
* 自前モデルは前処理なしのMulti-Head Attention(rnn, cnnを一部含む）だった

### submit
![](../images/kaggle_activity.png)
* 典型的な最後に焦るタイプでした


## 開催中の動き
### 2019年11月〜年末休み
* [A new baseline for DSB 2019 - Catboost model](https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model)
を参考をforkしてとりあえずsubmit
    * kaggleのお作法を学ぶ(notebookをそのまま提出する形式だったのでイメージと違い少し焦った）

* kaggleではとりあえず勾配ブースティング木と特徴量分析が主流であることを諸々の記事や本から思い知る
    * [kaggle初心者の私が3ヶ月でソロゴールドを獲得した方法](https://www.rco.recruit.co.jp/career/engineer/blog/kaggle_by_novice_engineer/)
    * [Kaggleで勝つデータ分析の技術](https://www.amazon.co.jp/dp/B07YTDBC3Z/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1)
    * 先人の知恵の上に生きていることを実感しました😇
    
### 2019年年末
* 勾配ブースティングのハイスコアカーネルをforkする
    * これ、ひたすら考察する必要があるなと感じ分が悪いと感じた
    * 逆に特徴量を作りがいがあると感じたが、今回は全てをニューラルネットワークに任せることに決めた
### 2020年年明け
* RNNレイヤーのハイパーパラメータチューニングをしながらこたつでみかんを食べる　
### 終盤
* Attentionモデル
